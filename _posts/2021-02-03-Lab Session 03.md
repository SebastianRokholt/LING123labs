---
title: Lab Session 03
date: 2021-02-02 15:53:00 +0100
categories: [Labs]
tags: [shell, scripting, bash, zsh, awk, gawk, word-frequencies, substitution, ciphers, n-grams, RStudio, R]
pin: false
math: true
---

Start by completing the exercises from
[Lab Session 02](https://sebastianrokholt.github.io/LING123labs/posts/Lab-Session-02/) if you haven't done so already.

The lecture notes for lecture 3 can be found
[here](https://lingkurs.h.uib.no/webroot/index.php?page=scripting/scriptfiles2&lang=en&course=ling123).
<br>

---


## Part 1) Word frequencies and N-grams

### Exercise 1.1: Script files and word frequencies<br>

a) Recreate [this example](https://lingkurs.h.uib.no/webroot/index.php?page=scripting/scriptfiles2&lang=en&course=ling123)
(`tokenize.sh` + count word frequencies) and send the output to a file. Compare this result with a frequency list
obtained otherwise, for instance, with [Antconc](https://www.laurenceanthony.net/software/antconc/). <br>
b) Create a script file `freq.sh` to make a frequency list of a tokenized file given as argument.
Try to combine it with the script for tokenization. <br>
c) Make a frequency list of a larger text, then select lines matching a regexp, e.g. words with three letters or less.
How do frequencies of shorter words compare to frequencies of longer words? <br>
<br>

---


 The next exercise requires [R](https://www.r-project.org/) and [RStudio](https://rstudio.com/products/rstudio/download/).
 Some of you might not have any experience with using R, so you might want to check out a short primer first.
> Here's what you need to know for now: <br>
> 1. [Installing R and RStudio](https://techvidvan.com/tutorials/install-r/#install-r-windows). <br>
> 2. Create a new R file in RStudio and store it in a folder of your choice ("File" --> "Save As"). <br>
> 3. [Download](https://lingkurs.h.uib.no/webroot/static/sherlock-freq.csv) the sherlock-freq.csv file <br>
> and store it in the same folder as your RStudio file.
> 4. Import the dataset by running this line of code: ```freqlist = read.table("LING123/sherlock-freq.csv")``` <br>
>
> NB! Use the relative filepath to `sherlock-freq.csv` from where you stored the R file.
> On Windows you might have to specify the folder (for me that would be 'LING123', as in the example above),
> even though the R file and the .csv actually are in the same folder.
> Pay attention to the Unix-style '/' in the pathname (as opposed to '\\').<br>

If you are interested in a proper introduction to R, I can recommend
[this free tutorial](https://www.youtube.com/watch?v=_V8eKsto3Ug). It covers the most basic stuff in a couple of hours,
and has a lot of great example code you can try out for yourself.
<br>

---


### Exercise 1.2: Plotting word frequencies in R <br>
a) Recreate the example from the [lecture notes](https://lingkurs.h.uib.no/webroot/index.php?page=scripting/plotfreq&lang=en&course=ling123)
in RStudio. <br>
b) Make observations about the distribution of the frequencies. <br>
c) The picture can be made clearer by using a logarithmic y axis.
Try `plot(Frequency,log="y")` instead. Then try making both axes logarithmic with `log="xy"`. <br>
d) Compare the result to the similar graph below, which shows word frequencies in different languages: <br>
![Zipf's Law](/assets/img/Zipfs-Law.png){: .normal}
_A plot of the rank versus frequency for the first 10 million words in 30 Wikipedias (dumps from October 2015)
on a log-log scale. <br>Obtained from [Wikipedia.org](https://en.wikipedia.org/w/index.php?title=Zipf%27s_law&oldid=1001240628)
on 30.01.2021_

### Exercise 1.3: N-grams
a) Execute [these commands](https://lingkurs.h.uib.no/webroot/index.php?page=scripting/ngrams&lang=en&course=ling123)
on a larger tokenized file. Create a frequency list of the resulting bigrams. <br>
> There's a very large text file you can use [here](https://mitt.uib.no/courses/27100/files?preview=3088069).
> You will of course need to tokenize it first :) <br>

b) Create a list of trigrams for the same file. Compare the number of trigrams with the number of bigrams. <br>
<br>

---


## Part 2) Ciphers and string substitutions <br>
The `tr` command lets us translate one set of characters to another, which allows us to create ciphers.
`tr` can take a file (specified as the third argument to the command) or user input (when no third argument is specified).
Here's an example:

```shell
`tr` 'abcdefghijklmnopqrstuvwxyz' 'qwertyuiopasdfghjklzxcvbnm'

> hello
itssg

> a very secret message
q ctkn ltektz dtllqut
```
> Reminder: Use `ctrl+c` / `cmd+c` to interrupt programs running in the shell.


### Exercise 2.1: Ciphers
a) Create a script `decrypt.sh` which turns the ciphertext produced by Koenraad's `encrypt.sh` back to normal.
The following workflow should give the original file:
```shell
source encrypt.sh < chess.txt | source decrypt.sh
```

b) Extend the strings to include the characters `æøåÆØÅ` (if your implementation of `tr` supports multi-byte characters),
and also digits, space and punctuation. Consider a less systematic ordering of the characters in the second string.


### Exercise 2.2: String substitutions
Reproduce the lecture [example code](https://lingkurs.h.uib.no/webroot/index.php?page=scripting/sed&lang=en&course=ling123)
with `(EUR|NOK|USD)` instead of `kr\.?.` Now you have two groups. Use `\2` instead of `kroner` in the replacement.


### Exercise 2.3: String substitutions (2)

a) Some accented vowels are missing from the
[example](https://lingkurs.h.uib.no/webroot/index.php?page=scripting/sed2&lang=en&course=ling123) in the lecture notes.
Add them. <br>
b) Replace empty onsets or codas with 0. <br>
c) After reading the chapter on
[cutting columns](https://lingkurs.h.uib.no/webroot/index.php?page=scripting/columns&lang=en&course=ling123),
cut the vowel column from this comma-separated output and produce a graph of the frequencies of the vowels. <br>
<br>

---


## Part 3: Additional exercises
These exercises are slightly more challenging. See if you are able to solve them all!
Let the seminar leader know if you are stuck, and you might get a hint... <br>


### Exercise 3.1: Word frequencies (extra)
a) Tokenize [The Bible](https://mitt.uib.no/courses/27100/files?preview=3088069) and save it to a new file
`bible-tokens.txt`. <br>
b) Retrieve all words from `bible-tokens.txt` which contain the letter *A* (case insensitive)
non-initially and non-finally. Get the frequencies for these words and sort them by highest occurence, like this:

```
16117 word number one
11695 word number two
5877 word number three
...
```
c) Use `egrep` to only retrieve words from `bible-tokens.txt` that are five letters long or more,
then count and sort them like above. <br>
d) Out of all words in the text, how many percent of them are five letters or longer and used more than once? <br>
> Tip: &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;
>  $$\dfrac{\text{amount of long words which occur more than once}}{\text{total number of words in the text}}$$

d) Write a shell script that can take a regular expression (argument `$1`) and a file name (argument `$2`) from the user,
and output a frequency list like in the exercises above. <br>



### Exercise 3.2: N-grams
a) Find all trigrams in `chess.txt` containing the word *det*. Afterwards, find only trigrams containing *det* as the
first word, middle word, then last word. <br>
b) Why can it be useful to differentiate where the word occurs in the N-grams? <br>



### Exercise 3.3: String substitutions
Using `sed`, create a shell script which reformats dates written as *DD.MM.YYYY* to *YYYY-MM-DD*. <br>
